{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "satisfied-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, 'Classes/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import current_process\n",
    "\n",
    "from ScoreGetter import ScoreGetter\n",
    "from dataset_utils import checkIfEarlyMidEnd\n",
    "from dataset_utils import encodeBoard\n",
    "from dataset_utils import getColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "opponent-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Datasets/raw_dataset_13M.csv')\n",
    "boards = df['board'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-semester",
   "metadata": {},
   "source": [
    "#### We load an engine to get a score from the positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "balanced-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_getter = ScoreGetter('/home/gaetan/Téléchargements/stockfish/stockfish', 'eval', 'go depth 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-balance",
   "metadata": {},
   "source": [
    "#### We create our dataset by getting an equal number of start, middle and end game positions and encoding them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "funded-soundtrack",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting and encoding:   0%|          | 1/10000000 [00:00<477:23:12,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting and encoding:  10%|█         | 1000099/10000000 [20:15<571:43:07,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting and encoding:  20%|██        | 2000090/10000000 [40:37<620:07:20,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting and encoding:  30%|███       | 3000088/10000000 [1:01:03<529:48:27,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting and encoding:  40%|████      | 4000088/10000000 [1:21:30<424:43:36,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting and encoding:  50%|█████     | 5000092/10000000 [1:44:47<333:18:21,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting and encoding:  60%|██████    | 6000090/10000000 [2:05:16<274:05:11,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting and encoding:  70%|███████   | 7000001/10000000 [2:25:50<375:09:42,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting and encoding:  80%|████████  | 8000090/10000000 [2:46:31<132:52:09,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting and encoding:  90%|█████████ | 9000060/10000000 [3:07:13<81:28:06,  3.41it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting and encoding: 100%|██████████| 10000000/10000000 [3:27:53<00:00, 801.69it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(4000000, len(boards)):\\n    board = boards[i]\\n    part = checkIfEarlyMidEnd(board)\\n    \\n    if len(earlies) < batch_size and part == \"early_game\":\\n        earlies.append(np.append(encodeBoard(board), score_getter.getScore(board)))\\n        pbar.update(1)\\n    \\n    elif len(mids) < batch_size and part == \"mid_game\":\\n        mids.append(np.append(encodeBoard(board), score_getter.getScore(board)))\\n        pbar.update(1)\\n        \\n    elif len(ends) < batch_size and part == \"end_game\":\\n        ends.append(np.append(encodeBoard(board), score_getter.getScore(board)))\\n        pbar.update(1)\\n    \\n    if len(earlies) >= batch_size and len(mids) >= batch_size and len(ends) >= batch_size:\\n        break\\n    \\npbar.close()\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_size = 1000000\n",
    "batch_size = total_size / 3.0\n",
    "\n",
    "earlies = []\n",
    "mids = []\n",
    "ends = []\n",
    "\n",
    "\n",
    "current = current_process()\n",
    "pos = current._identity[0]-1 if len(current._identity) > 0 else 0\n",
    "pbar = tqdm(total=total_size*10, desc='Splitting and encoding', position=pos)\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print(i+1)\n",
    "    data = []\n",
    "    for j in range(i * 1000000, i * 1000000 + total_size):\n",
    "        board = boards[j]\n",
    "        data.append(np.append(encodeBoard(board), score_getter.getScore(board)))\n",
    "        pbar.update(1)\n",
    "    df = pd.DataFrame(data, columns=np.append(getColumns(), 'cp (Stockfish 13)'))\n",
    "    df.to_csv('Datasets/dataset' + str(i+1) + '.csv', index=False)\n",
    "    \n",
    "pbar.close()\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "for i in range(4000000, len(boards)):\n",
    "    board = boards[i]\n",
    "    part = checkIfEarlyMidEnd(board)\n",
    "    \n",
    "    if len(earlies) < batch_size and part == \"early_game\":\n",
    "        earlies.append(np.append(encodeBoard(board), score_getter.getScore(board)))\n",
    "        pbar.update(1)\n",
    "    \n",
    "    elif len(mids) < batch_size and part == \"mid_game\":\n",
    "        mids.append(np.append(encodeBoard(board), score_getter.getScore(board)))\n",
    "        pbar.update(1)\n",
    "        \n",
    "    elif len(ends) < batch_size and part == \"end_game\":\n",
    "        ends.append(np.append(encodeBoard(board), score_getter.getScore(board)))\n",
    "        pbar.update(1)\n",
    "    \n",
    "    if len(earlies) >= batch_size and len(mids) >= batch_size and len(ends) >= batch_size:\n",
    "        break\n",
    "    \n",
    "pbar.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "everyday-principle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata = earlies + mids + ends\\nrandom.shuffle(data)\\nlen(data)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data = earlies + mids + ends\n",
    "random.shuffle(data)\n",
    "len(data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "talented-karaoke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf = pd.DataFrame(data, columns=np.append(getColumns(), 'cp (Stockfish 13)'))\\ndf.to_csv('Datasets/dataset5.csv', index=False)\\ndf.head()\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df = pd.DataFrame(data, columns=np.append(getColumns(), 'cp (Stockfish 13)'))\n",
    "df.to_csv('Datasets/dataset5.csv', index=False)\n",
    "df.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-southwest",
   "metadata": {},
   "source": [
    "#### We create a test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "contained-dallas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntest_size = 1000000\\ntests = []\\n\\ncurrent = current_process()\\npos = current._identity[0]-1 if len(current._identity) > 0 else 0\\npbar = tqdm(total=test_size, desc='Encoding', position=pos)\\n\\ntot_size = boards.shape[0]\\nfor i in range(test_size):\\n    idx = np.random.randint(tot_size)\\n    tests.append(np.append(encodeBoard(boards[idx]), score_getter.getScore(boards[idx])))\\n    pbar.update(1)\\npbar.close()\\n\\nlen(tests)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "test_size = 1000000\n",
    "tests = []\n",
    "\n",
    "current = current_process()\n",
    "pos = current._identity[0]-1 if len(current._identity) > 0 else 0\n",
    "pbar = tqdm(total=test_size, desc='Encoding', position=pos)\n",
    "\n",
    "tot_size = boards.shape[0]\n",
    "for i in range(test_size):\n",
    "    idx = np.random.randint(tot_size)\n",
    "    tests.append(np.append(encodeBoard(boards[idx]), score_getter.getScore(boards[idx])))\n",
    "    pbar.update(1)\n",
    "pbar.close()\n",
    "\n",
    "len(tests)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "colored-forwarding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf = pd.DataFrame(tests, columns = np.append(getColumns(), 'cp (Stockfish 13)'))\\ndf.to_csv('Datasets/test_dataset.csv', index=False)\\ndf.head()\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df = pd.DataFrame(tests, columns = np.append(getColumns(), 'cp (Stockfish 13)'))\n",
    "df.to_csv('Datasets/test_dataset.csv', index=False)\n",
    "df.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-cemetery",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
