{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing hyperparameters for GAiA's neural network\n",
    "\n",
    "In this notebook, we are trying different numbers of SE-ResNet blocks for our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"lib/\")\n",
    "sys.path.insert(1, \"model/\")\n",
    "from GAiA_network import GAiA_Network, coeff_determination\n",
    "from dataset_utils import read_many_hdf5, board_shape, encode_position, decode_position\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import platform\n",
    "if platform.system() == \"Darwin\":\n",
    "    %config InlineBackend.figure_format=\"retina\"  # For high DPI display\n",
    "\n",
    "if tf.test.gpu_device_name(): \n",
    "  print(f\"Default GPU Device: {tf.test.gpu_device_name()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are loading our training dataset and we are using it to build different training and validation data\n",
    "for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/media/gaetan/HDD/IA/Chess/Datasets/SE_ResNet/\"\n",
    "positions, scores = read_many_hdf5(79659, directory, \"_train\")\n",
    "positions = positions[:250000]\n",
    "scores = scores[:250000]\n",
    "\n",
    "nb_models = 4\n",
    "positions_train, scores_train = [], []\n",
    "positions_valid, scores_valid = [], []\n",
    "for i in range(nb_models):\n",
    "  positions_train_t, positions_valid_t, scores_train_t, scores_valid_t = train_test_split(\n",
    "    positions, scores, test_size=0.2, random_state=42+i)\n",
    "  positions_train.append(positions_train_t)\n",
    "  positions_valid.append(positions_valid_t)\n",
    "  scores_train.append(scores_train_t)\n",
    "  scores_valid.append(scores_valid_t)\n",
    "print(f\"Training sets shape ≈ {positions_train[0].shape}, Validation sets shape ≈ {positions_valid[0].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create several models with an increasing number of SE-ResNet blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "offset_blocks = 6\n",
    "filters = 128\n",
    "for i in range(1, nb_models+1):\n",
    "  model = GAiA_Network(board_shape, {\"filters\":filters, \"nb_blocks\":i+offset_blocks})\n",
    "  model.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[coeff_determination])\n",
    "  models.append(model)\n",
    "models[0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 20\n",
    "histories = []\n",
    "for i, model in enumerate(models):\n",
    "  print(f\"Model {i+1}/{len(models)}...\", end=\" \")\n",
    "  history = model.fit(positions_train[i], scores_train[i], verbose=0, epochs=nb_epochs)\n",
    "  histories.append(history)\n",
    "  pred = model.predict(positions_train[i])\n",
    "  r2_score = coeff_determination(tf.convert_to_tensor(scores_train[i]), pred).numpy()\n",
    "  print(f\"Done. Training accuracy: {r2_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation_results(histories, validation_Xs, validation_ys, path=None, ext=\"pdf\"):\n",
    "  epochs = range(1, nb_epochs + 1)\n",
    "\n",
    "  f, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "  _, ax_score  = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "  line_styles = [\"-\",\"--\",\"-.\",\":\"]\n",
    "\n",
    "  for i, history in enumerate(histories):\n",
    "    X_valid = validation_Xs[i]\n",
    "    y_valid = validation_ys[i]\n",
    "\n",
    "    loss = history.history[\"loss\"]\n",
    "    score = history.history[\"coeff_determination\"]\n",
    "    axs[0].plot(epochs, loss, line_styles[i], label=f\"{i + offset_blocks + 1} SE-ResNet blocks\")\n",
    "\n",
    "    axs[1].plot(epochs, score, line_styles[i], label=f\"{i + offset_blocks + 1} SE-ResNet blocks\")\n",
    "\n",
    "    preds = models[i].predict(X_valid)\n",
    "    r2_score = coeff_determination(tf.convert_to_tensor(y_valid), preds).numpy()\n",
    "    ax_score.scatter(y_valid, preds, label = f\"{i + offset_blocks + 1} SE-ResNet blocks $R^2 = {r2_score:.2f}$\")\n",
    "\n",
    "\n",
    "  axs[0].set_xlabel(\"Epoch\")\n",
    "  axs[0].set_ylabel(\"(Mean Absolute Error)\")\n",
    "  axs[0].set_title('Training loss')\n",
    "  axs[1].set_xlabel(\"Epoch\")\n",
    "  axs[1].set_ylabel(\"($R^2$)\")\n",
    "  axs[1].set_title('Training score')\n",
    "  for ax in axs:\n",
    "    ax.legend()\n",
    "\n",
    "  if path:\n",
    "    f.savefig(path + \"_1.\" + ext)\n",
    "\n",
    "  ma = np.max(y_valid)\n",
    "  mi = np.min(y_valid)\n",
    "  x = np.linspace(ma, mi, 100)\n",
    "  ax_score.plot(x, x, \"r-.\", label = \"Predictions = True values\")\n",
    "  ax_score.set_xlabel(\"True values (centipawn)\")\n",
    "  ax_score.set_ylabel(\"Predictions (centipawn)\")\n",
    "  ax_score.set_title(\"Results on validation set\")\n",
    "  ax_score.legend()\n",
    "\n",
    "  if path:\n",
    "    plt.savefig(path + \"_2.\" + ext)\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "def get_best_model(models, validation_Xs, validation_ys):\n",
    "  preds = []\n",
    "  for i in range(len(models)):\n",
    "    pred = models[i].predict(validation_Xs[i])\n",
    "    r2_score = coeff_determination(tf.convert_to_tensor(validation_ys[i]), pred).numpy()\n",
    "    preds.append(r2_score)\n",
    "  idx = np.argmax(preds)+1\n",
    "  return models[idx], offset_blocks + idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_validation_results(histories, positions_valid, scores_valid, path=\"results/model_selection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all of our model perform well.  We pick the one that have the best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, nb_blocks = get_best_model(models, positions_valid, scores_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the hyperparameters of our model in order to train it with more data and epochs in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"nb_blocks\": nb_blocks, \"filters\": filters}\n",
    "print(config)\n",
    "output_file = open(\"model/hyperparameters.pickle\", \"wb\")\n",
    "pickle.dump(config, output_file)\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
